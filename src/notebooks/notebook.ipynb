{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fluF3_oOgkWF"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:08.741384Z",
     "iopub.status.busy": "2023-10-27T05:56:08.741137Z",
     "iopub.status.idle": "2023-10-27T05:56:08.745307Z",
     "shell.execute_reply": "2023-10-27T05:56:08.744605Z"
    },
    "id": "AJs7HHFmg1M9"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Keywords recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:11.022612Z",
     "iopub.status.busy": "2023-10-27T05:56:11.022297Z",
     "iopub.status.idle": "2023-10-27T05:56:14.097093Z",
     "shell.execute_reply": "2023-10-27T05:56:14.096151Z"
    },
    "id": "dzLKpmZICaWN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from IPython import display\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:14.101666Z",
     "iopub.status.busy": "2023-10-27T05:56:14.101202Z",
     "iopub.status.idle": "2023-10-27T05:56:18.442466Z",
     "shell.execute_reply": "2023-10-27T05:56:18.441731Z"
    },
    "id": "2-rayb7-3Y0I"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/Users/michalsh/Documents/[03]Nauka/project_topical_research/MobileSensingProject/data/combined_wav'\n",
    "\n",
    "data_dir = pathlib.Path(DATASET_PATH)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BgvFq3uYiS5G"
   },
   "source": [
    "Print commands in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:18.446567Z",
     "iopub.status.busy": "2023-10-27T05:56:18.446315Z",
     "iopub.status.idle": "2023-10-27T05:56:18.450951Z",
     "shell.execute_reply": "2023-10-27T05:56:18.450333Z"
    },
    "id": "70IBxSKxA1N9"
   },
   "outputs": [],
   "source": [
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "commands = commands[(commands != 'README.md') & (commands != '.DS_Store')]\n",
    "print('Commands:', commands)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ7GJjDvHqtt"
   },
   "source": [
    "Split data into train and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=data_dir,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    seed=0,\n",
    "    output_sequence_length=16000,\n",
    "    subset='both',\n",
    "    label_mode = \"categorical\"\n",
    "    )\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print()\n",
    "print(\"label names:\", label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppG9Dgq2Ex8R"
   },
   "source": [
    "This dataset only contains single channel audio, so use the `tf.squeeze` function to drop the extra axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:22.116136Z",
     "iopub.status.busy": "2023-10-27T05:56:22.115535Z",
     "iopub.status.idle": "2023-10-27T05:56:22.156053Z",
     "shell.execute_reply": "2023-10-27T05:56:22.155416Z"
    },
    "id": "Xl-tnniUIBlM"
   },
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "  audio = tf.squeeze(audio, axis=-1)\n",
    "  return audio, labels\n",
    "\n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EWXPphxm0B4m"
   },
   "source": [
    "## Convert waveforms to spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:23.808195Z",
     "iopub.status.busy": "2023-10-27T05:56:23.807498Z",
     "iopub.status.idle": "2023-10-27T05:56:23.812130Z",
     "shell.execute_reply": "2023-10-27T05:56:23.811463Z"
    },
    "id": "_4CK75DHz_OR"
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=255, frame_step=128)\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnSuqyxJ1isF"
   },
   "source": [
    "Now, define a function for displaying a spectrogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:24.079181Z",
     "iopub.status.busy": "2023-10-27T05:56:24.078932Z",
     "iopub.status.idle": "2023-10-27T05:56:24.083788Z",
     "shell.execute_reply": "2023-10-27T05:56:24.083069Z"
    },
    "id": "e62jzb36-Jog"
   },
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax):\n",
    "  if len(spectrogram.shape) > 2:\n",
    "    assert len(spectrogram.shape) == 3\n",
    "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "  height = log_spec.shape[0]\n",
    "  width = log_spec.shape[1]\n",
    "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "  Y = range(height)\n",
    "  ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baa5c91e8603"
   },
   "source": [
    "Plot the example's waveform over time and the corresponding spectrogram (frequencies over time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:24.086741Z",
     "iopub.status.busy": "2023-10-27T05:56:24.086518Z",
     "iopub.status.idle": "2023-10-27T05:56:24.398568Z",
     "shell.execute_reply": "2023-10-27T05:56:24.397948Z"
    },
    "id": "d2_CikgY1tjv"
   },
   "outputs": [],
   "source": [
    "for example_audio, example_labels in train_ds.take(1):  \n",
    "  print(example_audio.shape)\n",
    "  print(example_labels.shape)\n",
    "waveform = example_audio[2]\n",
    "spectrogram = get_spectrogram(waveform)\n",
    "\n",
    "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
    "timescale = np.arange(waveform.shape[0])\n",
    "axes[0].plot(timescale, waveform.numpy())\n",
    "axes[0].set_title('Waveform')\n",
    "axes[0].set_xlim([0, 16000])\n",
    "\n",
    "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "axes[1].set_title('Spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyYXjW07jCHA"
   },
   "source": [
    "Now, create spectrogram datasets from the audio datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:24.402712Z",
     "iopub.status.busy": "2023-10-27T05:56:24.402476Z",
     "iopub.status.idle": "2023-10-27T05:56:24.406185Z",
     "shell.execute_reply": "2023-10-27T05:56:24.405586Z"
    },
    "id": "mAD0LpkgqtQo"
   },
   "outputs": [],
   "source": [
    "def make_spec_ds(ds):\n",
    "  return ds.map(\n",
    "      map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
    "      num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:24.409297Z",
     "iopub.status.busy": "2023-10-27T05:56:24.409049Z",
     "iopub.status.idle": "2023-10-27T05:56:24.641009Z",
     "shell.execute_reply": "2023-10-27T05:56:24.640378Z"
    },
    "id": "yEVb_oK0oBLQ"
   },
   "outputs": [],
   "source": [
    "train_spectrogram_ds = make_spec_ds(train_ds)\n",
    "val_spectrogram_ds = make_spec_ds(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:24.644995Z",
     "iopub.status.busy": "2023-10-27T05:56:24.644366Z",
     "iopub.status.idle": "2023-10-27T05:56:24.929009Z",
     "shell.execute_reply": "2023-10-27T05:56:24.928161Z"
    },
    "id": "EaM2q5aGis-d"
   },
   "outputs": [],
   "source": [
    "for example_spectrograms, example_spect_labels in train_spectrogram_ds.take(1):\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5KdY8IF8rkt"
   },
   "source": [
    "## Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:26.283266Z",
     "iopub.status.busy": "2023-10-27T05:56:26.283030Z",
     "iopub.status.idle": "2023-10-27T05:56:27.762045Z",
     "shell.execute_reply": "2023-10-27T05:56:27.761397Z"
    },
    "id": "ALYz7PFCHblP"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "input_shape = example_spectrograms.shape[1:]\n",
    "print('Input shape:', input_shape)\n",
    "num_labels = len(label_names)\n",
    "\n",
    "norm_layer = layers.Normalization()\n",
    "norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "        tf.keras.layers.Resizing(32, 32),\n",
    "        tf.keras.layers.Normalization(),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(4, activation=\"softmax\"),\n",
    "        ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:27.773915Z",
     "iopub.status.busy": "2023-10-27T05:56:27.773642Z",
     "iopub.status.idle": "2023-10-27T05:56:27.788886Z",
     "shell.execute_reply": "2023-10-27T05:56:27.788286Z"
    },
    "id": "wFjj7-EmsTD-"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\",\n",
    "                       tf.keras.metrics.Precision(),\n",
    "                       tf.keras.metrics.Recall(),\n",
    "                       tf.keras.metrics.F1Score()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:27.792517Z",
     "iopub.status.busy": "2023-10-27T05:56:27.791934Z",
     "iopub.status.idle": "2023-10-27T05:56:39.980933Z",
     "shell.execute_reply": "2023-10-27T05:56:39.979945Z"
    },
    "id": "ttioPJVMcGtq"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "history = model.fit(\n",
    "    train_spectrogram_ds,\n",
    "    validation_data=val_spectrogram_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjpCDeQ4mUfS"
   },
   "source": [
    "Let's plot the training and validation loss curves to check how your model has improved during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T05:56:39.985095Z",
     "iopub.status.busy": "2023-10-27T05:56:39.984529Z",
     "iopub.status.idle": "2023-10-27T05:56:40.300844Z",
     "shell.execute_reply": "2023-10-27T05:56:40.300207Z"
    },
    "id": "nzhipg3Gu2AY"
   },
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [Categorical CrossEntropy]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [%]')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "CPU",
  "colab": {
   "collapsed_sections": [],
   "name": "simple_audio.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
